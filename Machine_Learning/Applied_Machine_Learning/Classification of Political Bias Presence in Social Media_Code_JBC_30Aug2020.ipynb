{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Machine Learning \n",
    "## Classification of Political Bias Presence in Social Media\n",
    "- Joe Cruz \n",
    "- 28Aug2020\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script is designed to generate learning models for the dataset found in the Political-media-DFE.csv. The purpose of these learning models are to perform classification of text data from social media (Twitter and Facebook) and determine whether or not they have a poltiical bias (either neutral or partisan). The learning models used in this script are as follows: Multinomial Naive Bayes, LinearSVC, and Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The name of the dataset used is called Classification of Pol Social, where the file name of the dataset is called\n",
    "Political-media-DFE.csv. The dataset can be found at https://data.world/crowdflower/classification-of-pol-social"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Required Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the preprocessor function for cleaning up the text from the data sheet\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create instance of object to hold data, pulls data from the 'bias' and 'text' columns in the data sheet\n",
    "posts = pd.read_csv('Political-media-DFE.csv',encoding='latin1')[['bias','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          bias                                               text  \\\n",
      "0     partisan  RT @nowthisnews: Rep. Trey Radel (R- #FL) slam...   \n",
      "1     partisan  VIDEO - #Obamacare:  Full of Higher Costs and ...   \n",
      "2      neutral  Please join me today in remembering our fallen...   \n",
      "3      neutral  RT @SenatorLeahy: 1st step toward Senate debat...   \n",
      "4     partisan  .@amazon delivery #drones show need to update ...   \n",
      "...        ...                                                ...   \n",
      "4995  partisan  I applaud Governor PerryÛªs recent decision t...   \n",
      "4996  partisan  Today, I voted in favor of H.R. 5016 - Financi...   \n",
      "4997   neutral  (Taken from posted WOKV interview)   Congressm...   \n",
      "4998   neutral  Join me next week for a town hall in Ocala! I'...   \n",
      "4999   neutral  Foreign Affairs Committee Hearing on Syria. I ...   \n",
      "\n",
      "                                           cleaned_text  \n",
      "0     rt nowthisnews rep trey radel r fl slams obama...  \n",
      "1     video obamacare full of higher costs and broke...  \n",
      "2     please join me today in remembering our fallen...  \n",
      "3     rt senatorleahy 1st step toward senate debate ...  \n",
      "4      amazon delivery drones show need to update la...  \n",
      "...                                                 ...  \n",
      "4995  i applaud governor perry ûªs recent decision t...  \n",
      "4996  today i voted in favor of h r 5016 financial s...  \n",
      "4997   taken from posted wokv interview congressman ...  \n",
      "4998  join me next week for a town hall in ocala i l...  \n",
      "4999  foreign affairs committee hearing on syria i r...  \n",
      "\n",
      "[5000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#names columns 'bias' and 'text'\n",
    "posts.columns = ['bias','text']\n",
    "posts = posts.reset_index(drop=True)\n",
    "\n",
    "# Clean tweet text of HTML, etc.\n",
    "posts['cleaned_text'] = posts.text.map(preprocessor)\n",
    "\n",
    "# object is printed to view current status of the object, as we currently have 3 columns: 'bias', 'text', and 'cleaned_text'.\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating another object for creating the class analysis\n",
    "dataset= posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bias            0\n",
       "text            0\n",
       "cleaned_text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether there are any null data points in the data set that is being imported to the data object. Luckily there \n",
    "#are no null values\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     3689\n",
      "partisan    1311\n",
      "Name: bias, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Analysis: \\nSample Data Distribution')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generating a bar graph to symbolize the class analysis (number of data points in the dataset associated with each class)\n",
    "#Since this is a binary classification, the two classes are neutral or partisan.\n",
    "dataset.columns\n",
    "print(dataset['bias'].value_counts())\n",
    "figure=dataset['bias'].value_counts().plot(kind='bar', rot=0)\n",
    "figure.set_title('Class Analysis: \\nSample Data Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          bias                                       cleaned_text\n",
      "0     partisan  rt nowthisnews rep trey radel r fl slams obama...\n",
      "1     partisan  video obamacare full of higher costs and broke...\n",
      "2      neutral  please join me today in remembering our fallen...\n",
      "3      neutral  rt senatorleahy 1st step toward senate debate ...\n",
      "4     partisan   amazon delivery drones show need to update la...\n",
      "...        ...                                                ...\n",
      "4995  partisan  i applaud governor perry ûªs recent decision t...\n",
      "4996  partisan  today i voted in favor of h r 5016 financial s...\n",
      "4997   neutral   taken from posted wokv interview congressman ...\n",
      "4998   neutral  join me next week for a town hall in ocala i l...\n",
      "4999   neutral  foreign affairs committee hearing on syria i r...\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# removes the original text column from the object. Since we now have a cleaned text, it is best to remove the column and ensure\n",
    "#our object only holds the values of data we need to use.\n",
    "posts.drop(columns = ['text'],axis =1, inplace=True)\n",
    "\n",
    "# object is printed to view current status of the object, as we currently have 2 columns: 'bias'  and 'cleaned_text'.\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          bias                                       cleaned_text\n",
      "3294   neutral  it was great seeing you ryan davenport thank y...\n",
      "7      neutral  show your arizona pride choose your favorite s...\n",
      "3666   neutral  kode ksn reported on my local business tour in...\n",
      "771    neutral  getting my bubba watson on this am wafflehouse...\n",
      "352    neutral  rt md_dlds at the jobs forum featuring the us ...\n",
      "...        ...                                                ...\n",
      "1810   neutral  with john warner timkaine for shipyard keel la...\n",
      "2741  partisan  ben commonsense laws concerning things as powe...\n",
      "1416   neutral  no child should be held back due to zip codes ...\n",
      "4756   neutral  with steel salvaged from the twin towers forge...\n",
      "4471  partisan  if my constituents must suffer through the per...\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Reindex randomly\n",
    "posts = posts.reindex(index=np.random.permutation(posts.index))\n",
    "\n",
    "# object is printed to view current status of the object.\n",
    "# The indexes are now random instead of sequential.\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports the stopwords from ntlk.corpus and the alphabet \n",
    "#These 5 lines are for creating the stop word list that we need to create the lemmas for analysis\n",
    "#these remove common words that may not be necessary for our classification (ie a, the, etc)\n",
    "from nltk.corpus import stopwords\n",
    "from string import ascii_lowercase as alphabet\n",
    "\n",
    "import nltk\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop.extend([str(letter) for letter in alphabet])\n",
    "\n",
    "# This function is to split each indexed cleaned_text into a bag of words.\n",
    "def split_into_lemmas(post):\n",
    "    post = str(post).lower()\n",
    "    words = TextBlob(post).words\n",
    "    # for each word, take its \"base form\" = lemma z\n",
    "    return [word.lemma for word in words if word not in stop]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3294    [great, seeing, ryan, davenport, thank, droppi...\n",
      "7       [show, arizona, pride, choose, favorite, az, p...\n",
      "3666    [kode, ksn, reported, local, business, tour, s...\n",
      "771     [getting, bubba, watson, wafflehouse, cheese, ...\n",
      "352     [rt, md_dlds, job, forum, featuring, u, dept, ...\n",
      "                              ...                        \n",
      "1810    [john, warner, timkaine, shipyard, keel, layin...\n",
      "2741    [ben, commonsense, law, concerning, thing, pow...\n",
      "1416    [child, held, back, due, zip, code, proud, sup...\n",
      "4756    [steel, salvaged, twin, tower, forged, bow, us...\n",
      "4471    [constituent, must, suffer, peril, unintended,...\n",
      "Name: cleaned_text, Length: 5000, dtype: object\n",
      "\n",
      "\n",
      "          bias                                       cleaned_text\n",
      "3294   neutral  it was great seeing you ryan davenport thank y...\n",
      "7      neutral  show your arizona pride choose your favorite s...\n",
      "3666   neutral  kode ksn reported on my local business tour in...\n",
      "771    neutral  getting my bubba watson on this am wafflehouse...\n",
      "352    neutral  rt md_dlds at the jobs forum featuring the us ...\n",
      "...        ...                                                ...\n",
      "1810   neutral  with john warner timkaine for shipyard keel la...\n",
      "2741  partisan  ben commonsense laws concerning things as powe...\n",
      "1416   neutral  no child should be held back due to zip codes ...\n",
      "4756   neutral  with steel salvaged from the twin towers forge...\n",
      "4471  partisan  if my constituents must suffer through the per...\n",
      "\n",
      "[5000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#This is an example of the text after each text data is split into the bag of words.\n",
    "posts.cleaned_text.apply(split_into_lemmas)\n",
    "\n",
    "print(posts.cleaned_text.apply(split_into_lemmas))\n",
    "\n",
    "#Notice that when the posts object is called this is not seen, this is because the way it was performed does not change the \n",
    "#columns into a bag of words.\n",
    "print('\\n')\n",
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This bow_transformer is to vectorize the text data so that it can be analyzed. Otherwise, the model would not be able to\n",
    "#understand the inputs.\n",
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(posts.cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4538)\t1\n",
      "  (0, 5194)\t1\n",
      "  (0, 6899)\t1\n",
      "  (0, 10795)\t1\n",
      "  (0, 13073)\t1\n",
      "  (0, 13361)\t1\n",
      "  (0, 14700)\t1\n",
      "  (1, 1143)\t1\n",
      "  (1, 2049)\t1\n",
      "  (1, 2280)\t1\n",
      "  (1, 3541)\t1\n",
      "  (1, 3727)\t1\n",
      "  (1, 4249)\t1\n",
      "  (1, 5945)\t1\n",
      "  (1, 6050)\t1\n",
      "  (1, 7594)\t1\n",
      "  (1, 11387)\t1\n",
      "  (1, 11408)\t1\n",
      "  (1, 11760)\t1\n",
      "  (1, 12769)\t1\n",
      "  (1, 13642)\t1\n",
      "  (1, 14014)\t1\n",
      "  (1, 16223)\t1\n",
      "  (2, 3070)\t1\n",
      "  (2, 8242)\t1\n",
      "  :\t:\n",
      "  (4999, 7252)\t1\n",
      "  (4999, 7502)\t1\n",
      "  (4999, 8017)\t1\n",
      "  (4999, 8823)\t1\n",
      "  (4999, 8904)\t1\n",
      "  (4999, 9548)\t1\n",
      "  (4999, 10049)\t1\n",
      "  (4999, 10196)\t1\n",
      "  (4999, 10715)\t1\n",
      "  (4999, 11150)\t1\n",
      "  (4999, 11305)\t1\n",
      "  (4999, 11782)\t1\n",
      "  (4999, 11978)\t1\n",
      "  (4999, 12192)\t1\n",
      "  (4999, 12508)\t1\n",
      "  (4999, 12663)\t1\n",
      "  (4999, 12986)\t1\n",
      "  (4999, 13626)\t1\n",
      "  (4999, 14081)\t1\n",
      "  (4999, 14303)\t1\n",
      "  (4999, 14323)\t1\n",
      "  (4999, 14413)\t1\n",
      "  (4999, 14541)\t1\n",
      "  (4999, 14589)\t1\n",
      "  (4999, 15370)\t1\n",
      "\n",
      "sparse matrix shape: (5000, 16835)\n",
      "number of non-zeros: 95808\n",
      "sparsity: 0.11%\n"
     ]
    }
   ],
   "source": [
    "# Transform the posts in dataset to bag-of-words that are vectorized. This vectorization can be seen in the below print \n",
    "#statement.\n",
    "posts_bow = bow_transformer.transform(posts['cleaned_text'])\n",
    "print(posts_bow) \n",
    "print('\\nsparse matrix shape:', posts_bow.shape)\n",
    "print('number of non-zeros:', posts_bow.nnz)\n",
    "print('sparsity: %.2f%%' % (100.0 * posts_bow.nnz / (posts_bow.shape[0] * posts_bow.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts training shape:  (4000, 16835)\n",
      "Posts testing shape:   (1000, 16835)\n"
     ]
    }
   ],
   "source": [
    "# Split resulting posts_bow vector into traning and testing sets\n",
    "# For the purpose of accuracy, we will be utilizing 80% of the samples (5000 total samples, thus 4000) for training the model\n",
    "# Thus the other 20% (1000) of samples will be used for the model testing.\n",
    "posts_bow_train = posts_bow[:4000]\n",
    "posts_bow_test = posts_bow[4000:]\n",
    "posts_class_train = posts['bias'][:4000]\n",
    "posts_class_test = posts['bias'][4000:]\n",
    "\n",
    "#Below the the training and testing shapes are printed out. Notice that the training has 4000 samples with 16835 features\n",
    "#and the testing has 1000 samples with 16835 features.\n",
    "print(\"Posts training shape: \", posts_bow_train.shape)\n",
    "print(\"Posts testing shape:  \", posts_bow_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Multinomial Naive Bayes Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data assessment\n",
      "\n",
      "Accuracy:  0.91475\n",
      "Confusion Matrix:\n",
      " [[2810  154]\n",
      " [ 187  849]]\n",
      "(row=expected, col=predicted)\n",
      "\n",
      "Multinomial Naive Bayes Results: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.94      0.95      0.94      2964\n",
      "    partisan       0.85      0.82      0.83      1036\n",
      "\n",
      "    accuracy                           0.91      4000\n",
      "   macro avg       0.89      0.88      0.89      4000\n",
      "weighted avg       0.91      0.91      0.91      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Testing data assessment\n",
      "\n",
      "Accuracy:  0.762\n",
      "Confusion Matrix:\n",
      " [[592 133]\n",
      " [105 170]]\n",
      "(row=expected, col=predicted)\n",
      "\n",
      "Multinomial Naive Bayes Results: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.85      0.82      0.83       725\n",
      "    partisan       0.56      0.62      0.59       275\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.71      0.72      0.71      1000\n",
      "weighted avg       0.77      0.76      0.77      1000\n",
      "\n",
      "Obamacare spawning a new concept: \"medical homelessness.\"\n",
      "MNB Prediction:  [[0.13292597 0.86707403]] \n",
      "\n",
      "Please join me today in remembering our fallen heroes and honoring the men and women currently in military service for their sacrifices.\n",
      "MNB Prediction:  [[9.9998057e-01 1.9430000e-05]] \n",
      "\n",
      "who is going to see Antman today?\n",
      "MNB Prediction:  [[0.89648861 0.10351139]] \n",
      "\n",
      "vote republican\n",
      "MNB Prediction:  [[0.367427 0.632573]] \n",
      "\n",
      "vote for obama\n",
      "MNB Prediction:  [[0.34822884 0.65177116]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "#defining the model and training the model with the training data. Here we are using the Multinomial Naive Bayes model.\n",
    "post_class_clf  = MultinomialNB().fit(posts_bow_train, posts_class_train)\n",
    "\n",
    "#The model performs predictions based of the training data to establish how well the model is trained.\n",
    "#This is used to elucidate the results of the testing data and see if overfitting is a problem. \n",
    "predictions_training = post_class_clf.predict(posts_bow_train)\n",
    "\n",
    "print('Training data assessment\\n')\n",
    "\n",
    "print ('Accuracy: ', accuracy_score(posts_class_train, predictions_training))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(posts_class_train, predictions_training))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(\"\\nMultinomial Naive Bayes Results: \\n\")\n",
    "\n",
    "print(classification_report(posts_class_train, predictions_training))\n",
    "\n",
    "\n",
    "#The model performs predictions based of the testing data\n",
    "predictions = post_class_clf.predict(posts_bow_test)\n",
    "\n",
    "\n",
    "#These are the metrics for the predictions given by the model. The accuracy and confusion matrix are presented\n",
    "#as well as the classification report for the model (consists of precision, recall, f1-score and support for\n",
    "#each of the classifications, since binary classification only two classifications can be made)\n",
    "\n",
    "print('\\n\\n\\nTesting data assessment\\n')\n",
    "print ('Accuracy: ', accuracy_score(posts_class_test, predictions))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(posts_class_test, predictions))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(\"\\nMultinomial Naive Bayes Results: \\n\")\n",
    "\n",
    "print(classification_report(posts_class_test, predictions))\n",
    "\n",
    "\n",
    "#defines function to allow the model to take in an input as a string and classify it as either neutral or partisan. \n",
    "def predict_post_MNB(new_post): \n",
    "    new_sample = bow_transformer.transform([new_post])\n",
    "    print(new_post)\n",
    "    print(\"MNB Prediction: \", np.around(post_class_clf.predict_proba(new_sample), decimals=8),\"\\n\")\n",
    "\n",
    "    \n",
    "    \n",
    "#Below is some sample posts that are used to test the model's ablilty to classify input data. The first value given is the \n",
    "#probability that the post is likely neutral and the second value is the proability that the post is partisan. \n",
    "#These two text inputs are from the sample data and act as a control for the model. The first is for  \n",
    "predict_post_MNB('Obamacare spawning a new concept: \"medical homelessness.\"')\n",
    "predict_post_MNB('Please join me today in remembering our fallen heroes and honoring the men and women currently in military service for their sacrifices.')\n",
    "\n",
    "#These text inputs are randomly generated to see how the model does on newly input data that it has not seen.\n",
    "#As you can see, the model is able to classify the texts pretty well.\n",
    "predict_post_MNB('who is going to see Antman today?')\n",
    "predict_post_MNB('vote republican')\n",
    "predict_post_MNB('vote for obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Model for Cosine Similarity SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data assessment\n",
      "\n",
      "Accuracy:  0.869\n",
      "Confusion Matrix:\n",
      " [[2905   59]\n",
      " [ 465  571]]\n",
      "(row=expected, col=predicted)\n",
      "\n",
      "SVM Results: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.86      0.98      0.92      2964\n",
      "    partisan       0.91      0.55      0.69      1036\n",
      "\n",
      "    accuracy                           0.87      4000\n",
      "   macro avg       0.88      0.77      0.80      4000\n",
      "weighted avg       0.87      0.87      0.86      4000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Testing data assessment\n",
      "\n",
      "Accuracy:  0.766\n",
      "Confusion Matrix:\n",
      " [[679  46]\n",
      " [188  87]]\n",
      "(row=expected, col=predicted)\n",
      "\n",
      "SVM Results: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.78      0.94      0.85       725\n",
      "    partisan       0.65      0.32      0.43       275\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.72      0.63      0.64      1000\n",
      "weighted avg       0.75      0.77      0.74      1000\n",
      "\n",
      "Obamacare spawning a new concept: \"medical homelessness.\"\n",
      "SVM Prediction:  partisan \n",
      "\n",
      "Please join me today in remembering our fallen heroes and honoring the men and women currently in military service for their sacrifices.\n",
      "SVM Prediction:  neutral \n",
      "\n",
      "who is going to see Antman today?\n",
      "SVM Prediction:  neutral \n",
      "\n",
      "vote republican\n",
      "SVM Prediction:  partisan \n",
      "\n",
      "vote for obama\n",
      "SVM Prediction:  partisan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#defining the model and training the model with the training data. Here we are using the Linear SVC model with cosine_similarity\n",
    "post_class_svc = SVC(kernel=cosine_similarity, C=0.98).fit(posts_bow_train, posts_class_train)\n",
    "\n",
    "#The model performs predictions based of the training data to establish how well the model is trained.\n",
    "#This is used to elucidate the results of the testing data and see if overfitting is a problem. \n",
    "predictions_training = post_class_svc.predict(posts_bow_train)\n",
    "\n",
    "print('Training data assessment\\n')\n",
    "\n",
    "print ('Accuracy: ', accuracy_score(posts_class_train, predictions_training))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(posts_class_train, predictions_training))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(\"\\nSVM Results: \\n\")\n",
    "\n",
    "print(classification_report(posts_class_train, predictions_training))\n",
    "\n",
    "#The model performs predictions based of the testing data\n",
    "predictions = post_class_svc.predict(posts_bow_test)\n",
    "#These are the metrics for the predictions given by the model. The accuracy and confusion matrix are presented\n",
    "#as well as the classification report for the model (consists of precision, recall, f1-score and support for\n",
    "#each of the classifications, since binary classification only two classifications can be made)\n",
    "\n",
    "print('\\n\\n\\nTesting data assessment\\n')\n",
    "\n",
    "print ('Accuracy: ', accuracy_score(posts_class_test, predictions))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(posts_class_test, predictions))\n",
    "print('(row=expected, col=predicted)')\n",
    "print(\"\\nSVM Results: \\n\")\n",
    "\n",
    "\n",
    "print(classification_report(posts_class_test, predictions))\n",
    "\n",
    "\n",
    "#defines function to allow the model to take in an input as a string and classify it as either neutral or partisan. \n",
    "def predict_post_SVC(new_post): \n",
    "    new_sample = bow_transformer.transform([new_post])\n",
    "    print(new_post)\n",
    "    print(\"SVM Prediction: \", post_class_svc.predict(new_sample)[0], \"\\n\")\n",
    "\n",
    "    \n",
    "#Below is some sample posts that are used to test the model's ablilty to classify input data. The first value given is the probability\n",
    "#that the post is likely neutral and the second value is the proability that the post is partisan. \n",
    "#These two text inputs are from the sample data and act as a control for the model. \n",
    "predict_post_SVC('Obamacare spawning a new concept: \"medical homelessness.\"')\n",
    "predict_post_SVC('Please join me today in remembering our fallen heroes and honoring the men and women currently in military service for their sacrifices.')\n",
    "\n",
    "#These text inputs are randomly generated to see how the model does on newly input data that it has not seen.\n",
    "#As you can see, the model is able to classify the texts pretty well.\n",
    "predict_post_SVC('who is going to see Antman today?')\n",
    "predict_post_SVC('vote republican')\n",
    "predict_post_SVC('vote for obama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
